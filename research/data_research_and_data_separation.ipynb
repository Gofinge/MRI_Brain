{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Research & Data Separation of MRI_brain\n",
    "## 0. import package and set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import package\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class config(object):\n",
    "    data_root = '/Users/gofinge/Documents/Data/BrainMRI_raw/train'\n",
    "    data_name = 'train_pre_data.h5'\n",
    "    label_name = 'train_pre_label.csv'\n",
    "    \n",
    "    export_dir = '/Users/gofinge/Documents/Data/BrainMRI/'\n",
    "\n",
    "conf = config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. load data & reshape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "data\n(300, 1, 79, 95, 79)\n(300, 79, 95, 79)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load MRI\n",
    "f_raw = h5py.File(os.path.join(conf.data_root, conf.data_name), 'r')\n",
    "for key in f_raw.keys():\n",
    "    print(key)\n",
    "    print(f_raw[key].shape)\n",
    "\n",
    "mri = f_raw['data'][...]\n",
    "mri = np.squeeze(mri)\n",
    "print(mri.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1 0 0 1 0 1 2 1 1 2 2 0 1 2 1 0 2 1 2 1 0 1 2 2 1 0 1 0 1 1 0 2 1 1 1 1 0\n 1 1 1 2 1 2 0 1 2 1 2 0 1 2 2 1 2 1 1 2 1 2 1 1 2 1 0 2 1 0 0 0 1 2 0 1 0\n 1 1 1 1 2 0 1 0 1 1 1 2 1 2 0 1 2 1 1 1 1 2 1 0 1 0 0 2 1 1 1 1 1 1 0 1 1\n 2 2 1 2 2 0 1 0 2 1 0 2 2 0 1 2 2 0 1 1 1 1 1 1 1 1 2 0 0 0 0 0 2 0 1 1 1\n 0 2 1 0 1 2 0 1 2 2 1 1 0 2 2 1 0 2 1 1 2 1 2 1 0 0 1 1 1 1 1 1 0 2 1 1 1\n 2 1 1 1 1 2 0 0 2 1 2 1 2 1 1 2 1 0 2 1 1 1 0 1 2 2 0 2 1 0 1 0 1 0 2 1 2\n 1 1 0 1 1 1 1 1 2 1 1 1 1 1 0 1 2 1 2 2 0 0 1 0 0 1 0 2 1 1 0 1 2 0 2 2 2\n 0 1 1 0 1 0 2 1 2 1 2 1 1 1 2 2 1 0 1 1 1 2 1 1 1 0 2 1 2 1 2 1 1 0 2 1 2\n 1 1 0 2]\n<class 'numpy.ndarray'>\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load label\n",
    "labels = np.array(pd.read_csv(os.path.join(conf.data_root, conf.label_name))['label'])\n",
    "print(labels)\n",
    "print(type(labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. separate mri & labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# labels count\n",
    "index0 = np.where(labels == 0) # 68\n",
    "index1 = np.where(labels == 1) # 151\n",
    "index2 = np.where(labels == 2) # 81\n",
    "\n",
    "print(np.size(index0))\n",
    "print(np.size(index1))\n",
    "print(np.size(index2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "68\n151\n81\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(210, 79, 95, 79)\n(45, 79, 95, 79)\n(45, 79, 95, 79)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# separation\n",
    "labels.sort()\n",
    "test_idx = list(np.linspace(0, 299, num = 45, endpoint = False, dtype = int))\n",
    "val_idx = [x+1 for x in test_idx]\n",
    "train_idx = list(np.delete([i for i in range(300)], test_idx + val_idx, axis = 0))\n",
    "\n",
    "train_mri = mri[train_idx]\n",
    "val_mri = mri[val_idx]\n",
    "test_mri = mri[test_idx]\n",
    "\n",
    "train_labels = labels[train_idx]\n",
    "val_labels = labels[val_idx]\n",
    "test_labels = labels[test_idx]\n",
    "\n",
    "print(train_mri.shape)\n",
    "print(val_mri.shape)\n",
    "print(test_mri.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# save data\n",
    "def save_hdf5(data, labels, filename):\n",
    "    file = h5py.File(filename + '.h5','w')\n",
    "    file.create_dataset('data', data = data)\n",
    "    labels_str = [str(x) for x in labels]\n",
    "    np.savetxt(filename + '_labels.csv', labels_str, fmt = '%s')\n",
    "    \n",
    "    \n",
    "save_hdf5(train_mri, train_labels, os.path.join(conf.export_dir, 'train'))\n",
    "save_hdf5(val_mri, val_labels, os.path.join(conf.export_dir, 'val'))\n",
    "save_hdf5(test_mri, test_labels, os.path.join(conf.export_dir, 'test'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}